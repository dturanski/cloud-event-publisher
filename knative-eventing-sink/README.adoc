= Knative Eventing Sink


A Spring Cloud Stream Sink that generates Cloud Events for integrating Spring Cloud Data FLow pipelines with Knative eventing.

== Prerequisites

NOTE: the link:../README.adoc#prerequisites[prerequisites] for running this sample.

* Spring Cloud Data Flow Server with Kafka deployed in the same Kubernetes cluster as PFS.
* The Time source application for kafka/docker registered.

== How it works

This application acts as a bridge between Spring Cloud Stream or Spring Cloud Data Flow to Knative.
Even though it is implemented as a Spring Cloud Stream Sink, with the Kafka binder, it is deployed as a Knative event source, hence
not managed by Spring Cloud Data Flow.

This can be used to bridge any Spring Cloud Stream Source to a Knative eventing application. It publishes a Cloud Event for each Message it
receives on a Kafka topic.

NOTE: Currently only String payloads are supported.

Here we are using a named destination called `knative`.

```
dataflow>create stream --name knative-source "time > :knative
```

Then Deploy this application as a knative eventing source as follows:


== Build

Build and push the docker image to GCR. Provide your GCP project as a property.

```
cd knative-eventing-sink
./mvnw clean package jib:build -Dgcp.project=<your_GCP_project>
```
=== Running a sample on PFS

This is a variation of the documented samples that send events the `message dumper` service, e.g., https://github.com/knative/eventing-sources/blob/master/samples/gcp-pubsub-source/README.md[gcp-pubsub-source].

This example creates an eventing source that processes the output of a Spring Cloud Data Flow stream

The source publishes to a channel which the `message dumper` subscribes to.
The `message dumper` logs the contents of each message it receives.

NOTE: The PFS install includes and older version of Knative Eventing, these samples depend on setting up Knative Eventing as documented.

First, create a Channel:

```
kubectl apply -f config/channel-qux1.yaml
```
Next, subscribe the `message dumper` to the qux-1 channel.

```
kubectl apply -f config/subscriber-message-dumper.yaml
```

Create an Istio ServiceEntry so the eventing source can connect to the Kafka Broker:

```
kubectl apply -f config/kafka-service-entry.yaml
```


Edit `config/containersource-sample-event-source.yaml` and change the repository to the GCR repository where you published the eventing source image.
```
kubectl apply -f config/containersource-knative-eventing-sink.yaml
```

Soon, tou should see the eventing source and message dumper pods running in the default namespace, e.g.,
```
$kubectl get pods

NAME                                                  READY   STATUS    RESTARTS   AGE
pod/knative-eventing-sink-xzczd-5fb879c79d-vst2q      2/2     Running   0          2m
pod/message-dumper-00001-deployment-f5f5494cf-87tf6   3/3     Running   0          2m
```

The logs from the eventing source should show a message like this every second:

```
$kubectl logs -f cloud-event-source-xzczd-5fb879c79d-vst2q source

2018-12-20 19:25:17.424  INFO 1 --- [container-0-C-1] o.d.c.s.KnativeEventingSinkApplication   : Posting cloud event DefaultCloudEventImpl{specversion='0.2', type='org.springframework.cloud.dataflow.event', source=/scdf/time, id='ca90b0d0-a456-4039-b33b-b60f49f5fdd1', time=2018-12-20T19:25:17.424Z[GMT], schemaURL=null, contentType='text/plain', data="12/20/18 19:31:14"} to http://qux-1-channel.default.svc.cluster.local/
2018-12-20 19:25:17.433  INFO 1 --- [or-http-epoll-1] o.d.c.s.KnativeEventingSinkApplication   : status 202 ACCEPTED
```

And the message dumper logs:

```
$kubectl logs -f message-dumper-00001-deployment-f5f5494cf-87tf6 user-container

2018/12/20 19:31:14 Message Dumper received a message: POST / HTTP/1.1
Host: message-dumper.default.svc.cluster.local
Accept-Encoding: gzip
Content-Length: 236
Content-Type: application/cloudevents+json
User-Agent: Go-http-client/1.1
X-B3-Parentspanid: 57228dd7c31f1d94
X-B3-Sampled: 1
X-B3-Spanid: ac0ae42cce51ac20
X-B3-Traceid: 57228dd7c31f1d94
X-Forwarded-For: 127.0.0.1
X-Forwarded-Proto: http
X-Request-Id: 11b7c8d4-e643-9ae0-90c1-4bc68db78655

{"type":"org.springframework.cloud.dataflow.event","source":"/scdf/time","id":"7708c06f-1f76-4f1e-b340-68e6c7e39774","time":1545334274.264000000,"schemaURL":null,"contentType":"text/plain","data":"12/20/18 19:31:14","specVersion":"0.2"}
```

Terminate the event source, after a few minutes, the message dumper will terminate away since it is no longer receiving messages.
```
kubectl delete containersource.sources.eventing.knative.dev/knative-eventing-source
```

